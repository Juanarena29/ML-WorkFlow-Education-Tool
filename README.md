# ML WorkFlow Education Tool

An interactive web application for training Machine Learning models **without writing code**.

Designed both to **learn the fundamentals of Machine Learning** and to **use as a practical model training tool**.

---

## ğŸ¯ What is it?

ML Workflow is a Streamlit-based application that guides the user step by step through the complete Machine Learning workflow:

1. **Load data** â†’ Upload a CSV file  
2. **Detect types** â†’ Identify numerical variables, categorical variables, and the target  
3. **Clean data** â†’ Impute missing values, remove duplicates  
4. **Explore data (EDA)** â†’ Visualize distributions, correlations, and relationships 
5. **Train models** â†’ Select and train multiple algorithms  
6. **Analyze results** â†’ Compare metrics, inspect confusion matrices, ROC curves  
7. **Predict** â†’ Use trained models on new data  

---

## ğŸ“˜ LEARN Mode

The core of this project is its **educational mode**.

### Who is it for?

- Students who are just starting with Machine Learning  
- Curious learners who want to understand what is behind predictions  
- Anyone who prefers learning by doing, not just reading  

### What makes it different?

At every step of the workflow, LEARN mode provides **contextual explanations** that answer:

- **What am I looking at?** â†’ What the data, charts, and metrics mean  
- **Why does it matter?** â†’ The purpose of each step in the ML workflow  
- **What decisions am I making?** â†’ The implications of choosing one option over another  

For example:
- When loading a dataset, it explains what a dataset is and the different data types  
- When selecting the target, it explains the difference between regression and classification  
- During training, it explains what a train/test split is and why it is used  
- When reviewing results, it explains how to interpret accuracy, precision, recall, etc.  

### Philosophy

> **â€œThe most costly errors in Machine Learning are not in the model, but in the steps before it.â€**

This is not about running magical code and looking at numbers.  
It is about **understanding the process** in order to make better decisions when working with your own data.

---

## ğŸ”§ TOOL Mode

For users who already understand the process and only want a fast, practical tool to:

- Test different models on their own data  
- Easily compare algorithms  
- Export trained models  
- Generate predictions  

No additional explanations, a direct path to results.

---

## ğŸš€ Installation

### Requirements
- Python 3.10+

### Steps

```bash
# Clone the repository
git clone https://github.com/Juanarena29/ML-WorkFlow-Education-Tool.git
cd ML-WorkFlow-Education-Tool

# Create virtual environment
python -m venv venv

# Activate environment (Windows)
.\venv\Scripts\Activate.ps1

# Activate environment (Linux/Mac)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run the application
streamlit run HOME.py
```

---

## ğŸ“‚ Project structure

```
ML-WorkFlow-Education-Tool/
â”œâ”€â”€ HOME.py                 # Main page
â”œâ”€â”€ pages/                  # Workflow pages
â”‚   â”œâ”€â”€ 1-LoadDataset.py
â”‚   â”œâ”€â”€ 2-TypesDetection.py
â”‚   â”œâ”€â”€ 3-CleaningConfig.py
â”‚   â”œâ”€â”€ 4-EDA.py
â”‚   â”œâ”€â”€ 5-Training.py
â”‚   â”œâ”€â”€ 6-Results.py
â”‚   â””â”€â”€ 7-Prediction.py
â”œâ”€â”€ src/                    # Business logic
â”‚   â”œâ”€â”€ data/               # Loading, analysis, and cleaning
â”‚   â”œâ”€â”€ eda/                # Statistics and visualizations
â”‚   â”œâ”€â”€ ml/                 # Models, pipelines, and evaluation
â”‚   â””â”€â”€ utils/              # Session, constants, file handling
â”œâ”€â”€ tests/                  # Unit tests (pytest)
â”œâ”€â”€ assets/                 # Styling and example datasets
â”œâ”€â”€ models/                 # Exported models (.pkl)
â””â”€â”€ projectconfigs/         # Saved configurations
```

---

## ğŸ¤– Available models

### Classification
- Logistic Regression
- Random Forest
- Gradient Boosting
- SVC (Support Vector Classifier)
- XGBoost

### Regression
- Linear Regression
- Ridge
- Lasso
- Random Forest
- Gradient Boosting
- XGBoost

All models include:
- Automatic preprocessing (imputation, scaling, encoding)
- Optional GridSearchCV for hyperparameter optimization
- Complete evaluation metrics

---

## ğŸ“Š Metrics and visualizations

Classification
- Accuracy, Precision, Recall, F1-Score
- ROC AUC (binary classification)
- Confusion matrix (raw and normalized)
- ROC curve

### Regression
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)
- RÂ² (Coefficient of Determination)
- Residuals plot

---

## â˜ï¸ Streamlit Cloud deployment

The application automatically detects when it is running on Streamlit Cloud and applies limits to avoid resource saturation:

- Maximum 20,000 rows
- Maximum 100 columns
- Maximum 3 folds in GridSearchCV

No limits are applied in local mode.

---

## ğŸ§ª Tests

```bash
# Run all tests
pytest tests/ -v

# Run tests with coverage
pytest tests/ --cov=src
```

---

## ğŸ› ï¸ Tech stack

- **Frontend**: Streamlit
- **Machine Learning**: scikit-learn, XGBoost
- **Visualization**: Plotly
- **Data**: Pandas, NumPy

---

## ğŸ“ License

MIT

---


*If this project helps you learn Machine Learning, consider giving it a â­ on GitHub!*
